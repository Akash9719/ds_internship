{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\hp\\anaconda3\\lib\\site-packages (3.141.0)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from selenium) (1.25.11)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as Ec\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening web driver\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#giving url to webdriver\n",
    "url='https://www.naukri.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"942d80f79aa6d1b78cf6d00b3ccb7477\", element=\"05444047-2bef-41e2-9164-b864fd684749\")>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#searching xpath on webpage\n",
    "search_job=driver.find_element_by_xpath('//input[@class=\"sugInp\"]')\n",
    "search_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#giving input in search bar\n",
    "search_job.send_keys(\"business analyst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"942d80f79aa6d1b78cf6d00b3ccb7477\", element=\"7222ef81-9945-411a-bccc-0a86d0eb2e3c\")>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#searching xpath on webpage\n",
    "search_loc=driver.find_element_by_id(\"qsb-location-sugg\")\n",
    "search_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#giving input in search bar\n",
    "search_loc.send_keys(\"banglore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#searching data and pressing button\n",
    "search_button=driver.find_element_by_xpath('//button[@class=\"btn\"]')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"942d80f79aa6d1b78cf6d00b3ccb7477\", element=\"ad599c6b-a617-468b-84d8-88dddc521705\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"942d80f79aa6d1b78cf6d00b3ccb7477\", element=\"490c40ab-d8f7-49c7-8b4b-00f7577e5444\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"942d80f79aa6d1b78cf6d00b3ccb7477\", element=\"40a0759c-4959-49c7-9fa6-5169e1f5f8d5\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"942d80f79aa6d1b78cf6d00b3ccb7477\", element=\"08408a84-4ff9-4838-bcb8-bdf760effab9\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"942d80f79aa6d1b78cf6d00b3ccb7477\", element=\"b5c4c8aa-f828-42d5-8561-4c3986890229\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"942d80f79aa6d1b78cf6d00b3ccb7477\", element=\"6fe497fa-0798-42c0-8d93-1f4f594066c8\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"942d80f79aa6d1b78cf6d00b3ccb7477\", element=\"46b7d265-9d0f-477a-b9f0-6486fdb9b055\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"942d80f79aa6d1b78cf6d00b3ccb7477\", element=\"7487ad34-6229-45f4-a229-59d55ef3c1ae\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"942d80f79aa6d1b78cf6d00b3ccb7477\", element=\"545aa80a-0916-4e76-8504-91e9e584ea83\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"942d80f79aa6d1b78cf6d00b3ccb7477\", element=\"2d60c593-5600-4b7c-ab74-5b758390d881\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"942d80f79aa6d1b78cf6d00b3ccb7477\", element=\"50c6c74f-b7d0-42ec-8cd4-98905d2668ef\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"942d80f79aa6d1b78cf6d00b3ccb7477\", element=\"fab6aefc-ee59-4312-b795-c2ec437273c2\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"942d80f79aa6d1b78cf6d00b3ccb7477\", element=\"8b4ca84a-8cd4-4ed7-b789-1a7d7b883687\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"942d80f79aa6d1b78cf6d00b3ccb7477\", element=\"921fccfd-abde-4f25-955a-dde4e61448b4\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"942d80f79aa6d1b78cf6d00b3ccb7477\", element=\"08112442-7609-4d4c-a248-6cf2ea6f69dc\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"942d80f79aa6d1b78cf6d00b3ccb7477\", element=\"69bd37ca-c96d-4868-8f42-ba7fdc3dc510\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"942d80f79aa6d1b78cf6d00b3ccb7477\", element=\"4b8e7ad6-22ad-466e-b1ea-720288e75be3\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"942d80f79aa6d1b78cf6d00b3ccb7477\", element=\"d9e73106-5e02-42c4-af1c-8bacb088b6bf\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"942d80f79aa6d1b78cf6d00b3ccb7477\", element=\"8a375436-d4cd-4c04-872e-01197e255ee9\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"942d80f79aa6d1b78cf6d00b3ccb7477\", element=\"f7a6ddbb-c0ca-4e47-908a-6d40be66c844\")>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find jobs\n",
    "job_title=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "job_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tech Mahindra Hiring For Business Analyst (KYC)- Bangalore',\n",
       " 'Senior IT Business Analyst/ Requirements Engineer in IT',\n",
       " 'Business Analyst',\n",
       " 'Business Analyst',\n",
       " 'Regional Applications Business Analyst',\n",
       " 'Business Analyst: ADM',\n",
       " 'Business Analyst: ADM',\n",
       " 'Business Analyst - Operations',\n",
       " 'Business Analyst - Operations',\n",
       " 'Business Analyst - Risk Domain (VaR, Expected Shortfall, Tracking Erro',\n",
       " 'Market Data Business Analyst,',\n",
       " 'Business Analyst/ Sr Business Analyst/ Solution Architect',\n",
       " 'Business Analyst',\n",
       " 'Corporate Actions Business Analyst,',\n",
       " 'Maveric Systems_Full-time Job Opportunity_Temenos T24 Business Analyst',\n",
       " 'Business Analyst',\n",
       " 'Urgent Junior Business Analyst / Business Analyst / Senior Business An',\n",
       " 'Business Analyst with Salesforce',\n",
       " 'Senior Business Analyst',\n",
       " 'Senior Business Analyst - ( US Healthcare) - Permanent Opportunity']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_titles=[]\n",
    "for i in job_title:\n",
    "    job_titles.append(i.text)\n",
    "job_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"942d80f79aa6d1b78cf6d00b3ccb7477\", element=\"faf3f877-1cc3-4fa7-ab09-e7bf08c1b6fd\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"942d80f79aa6d1b78cf6d00b3ccb7477\", element=\"f21df352-1624-4d27-903d-d78393728512\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"942d80f79aa6d1b78cf6d00b3ccb7477\", element=\"3d56ee86-594a-480a-adb7-c9e134d3af4f\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"942d80f79aa6d1b78cf6d00b3ccb7477\", element=\"2b3fee4c-3dcd-492a-88cf-7255bc5b7172\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"942d80f79aa6d1b78cf6d00b3ccb7477\", element=\"bc0d00aa-404a-4b27-b28b-bf677ddc9f00\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"942d80f79aa6d1b78cf6d00b3ccb7477\", element=\"8d91a53a-0847-4d87-b60b-7b79607a4d45\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"942d80f79aa6d1b78cf6d00b3ccb7477\", element=\"8ce95566-4e6b-4cda-88f9-31afdb1891fd\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"942d80f79aa6d1b78cf6d00b3ccb7477\", element=\"1b1af019-6d8b-465b-9ac5-dd88eabd1dfb\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"942d80f79aa6d1b78cf6d00b3ccb7477\", element=\"f4a2c936-482c-4b2d-b23e-c593eca96a3f\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"942d80f79aa6d1b78cf6d00b3ccb7477\", element=\"da8cd7b1-9aec-4a0c-8586-8b7daf1d9a13\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"942d80f79aa6d1b78cf6d00b3ccb7477\", element=\"f2542205-fe06-4f0f-aa31-60acea27f28d\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"942d80f79aa6d1b78cf6d00b3ccb7477\", element=\"b2ae0002-aa02-4c11-b353-c407696de001\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"942d80f79aa6d1b78cf6d00b3ccb7477\", element=\"b42f4f3c-5802-49e2-8167-14a3e755962d\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"942d80f79aa6d1b78cf6d00b3ccb7477\", element=\"167bc44a-4339-4f0c-910b-790399ffea82\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"942d80f79aa6d1b78cf6d00b3ccb7477\", element=\"d2cd80c1-f812-4475-a349-8ac1692d0d79\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"942d80f79aa6d1b78cf6d00b3ccb7477\", element=\"7e501adb-d7da-4e76-9e86-6c9ab09e676f\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"942d80f79aa6d1b78cf6d00b3ccb7477\", element=\"f9d5d200-5d4d-47d6-af57-cc6d651dc46e\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"942d80f79aa6d1b78cf6d00b3ccb7477\", element=\"1cdfe0dc-b9bf-4f79-a08b-16d6f04bfdf5\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"942d80f79aa6d1b78cf6d00b3ccb7477\", element=\"32c70709-7282-4521-b4e7-8578ab409732\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"942d80f79aa6d1b78cf6d00b3ccb7477\", element=\"1d00092a-4a20-432e-b2b5-15d70abaf6dc\")>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find company name\n",
    "com_name=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "com_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tech mahindra ltd',\n",
       " 'Innoveo',\n",
       " 'Infosys Limited',\n",
       " 'Flipkart Internet Private Limited',\n",
       " 'AECOM India Private Limited',\n",
       " 'IBM India Pvt. Limited',\n",
       " 'IBM India Pvt. Limited',\n",
       " 'IBM India Pvt. Limited',\n",
       " 'IBM India Pvt. Limited',\n",
       " 'Oracle India Pvt. Ltd.',\n",
       " 'Luxoft',\n",
       " 'NetCracker Technology Solutions (India) Pvt Ltd',\n",
       " 'Altisource Business Solutions Pvt Ltd',\n",
       " 'Luxoft',\n",
       " 'Maveric Systems Limited',\n",
       " 'Exxon Mobil Corporation',\n",
       " 'Rapid Value IT Services Pvt Ltd',\n",
       " 'CONDUENT BUSINESS SERVICES INDIA LLP',\n",
       " 'Rupeek Fintech Pvt Ltd',\n",
       " 'Nalashaa Solutions India Pvt Ltd']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_names=[]\n",
    "for i in com_name:\n",
    "    company_names.append(i.text)\n",
    "company_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"942d80f79aa6d1b78cf6d00b3ccb7477\", element=\"9f5221e1-356f-41ec-a58b-2999e4102920\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"942d80f79aa6d1b78cf6d00b3ccb7477\", element=\"5ad6e085-a7a7-4da6-a3c3-63547261d988\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"942d80f79aa6d1b78cf6d00b3ccb7477\", element=\"90d4571c-1743-419e-a130-b3b37d020129\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"942d80f79aa6d1b78cf6d00b3ccb7477\", element=\"937a1eaf-d944-4913-be43-35dfd0aa799b\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"942d80f79aa6d1b78cf6d00b3ccb7477\", element=\"c421aea1-643b-4f42-9486-40cac2a41d1b\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"942d80f79aa6d1b78cf6d00b3ccb7477\", element=\"86841bd7-ffb1-4907-87a0-dfef21f4a9c2\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"942d80f79aa6d1b78cf6d00b3ccb7477\", element=\"7db6f2de-2351-44b8-bebd-66cd99073391\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"942d80f79aa6d1b78cf6d00b3ccb7477\", element=\"c92a56b4-3cbd-4edc-94aa-9e2b8f76896a\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"942d80f79aa6d1b78cf6d00b3ccb7477\", element=\"124c9626-9367-4590-8f34-20ea747ceba5\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"942d80f79aa6d1b78cf6d00b3ccb7477\", element=\"7355153d-cdc9-4d4b-9850-6a120e62c749\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"942d80f79aa6d1b78cf6d00b3ccb7477\", element=\"122ad184-c2ba-4be3-a434-214ed33a8579\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"942d80f79aa6d1b78cf6d00b3ccb7477\", element=\"1e93caf7-aba4-4274-95a6-262bd98f14c4\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"942d80f79aa6d1b78cf6d00b3ccb7477\", element=\"0d83a1a2-1c7b-4c47-ae78-cb444fccc5e5\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"942d80f79aa6d1b78cf6d00b3ccb7477\", element=\"93775019-1904-49dd-aa52-018c0a167994\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"942d80f79aa6d1b78cf6d00b3ccb7477\", element=\"765b4a02-d270-42b8-b0fe-2c8728b78bb7\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"942d80f79aa6d1b78cf6d00b3ccb7477\", element=\"87eaaec7-6484-43a3-978d-7fb060eb53ae\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"942d80f79aa6d1b78cf6d00b3ccb7477\", element=\"1844399a-f51d-48ee-9228-51238c533387\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"942d80f79aa6d1b78cf6d00b3ccb7477\", element=\"a65a7e46-484b-45c6-88d8-ed603b182b22\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"942d80f79aa6d1b78cf6d00b3ccb7477\", element=\"de483f5f-8bc1-4aa8-a073-25182f2cab16\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"942d80f79aa6d1b78cf6d00b3ccb7477\", element=\"2dfccb2e-48d3-4a4d-b298-4b15458150dd\")>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_location=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']//span\")\n",
    "job_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bangalore/Bengaluru',\n",
       " 'Chennai, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Hyderabad/Secunderabad, Pune, Gurgaon/Gurugram, Bangalore/Bengaluru, Delhi / NCR',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Pune, Chennai, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Kochi/Cochin, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Kolkata, Hyderabad/Secunderabad, Ahmedabad, Chennai, Bangalore/Bengaluru']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_locations=[]\n",
    "for i in job_location:\n",
    "    job_locations.append(i.text)\n",
    "job_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "experience=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']//span\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "experience_req=[]\n",
    "for i in experience:\n",
    "    experience_req.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tech Mahindra Hiring For Business Analyst (KYC...</td>\n",
       "      <td>tech mahindra ltd</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior IT Business Analyst/ Requirements Engin...</td>\n",
       "      <td>Innoveo</td>\n",
       "      <td>Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>6-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>Infosys Limited</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>Flipkart Internet Private Limited</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Regional Applications Business Analyst</td>\n",
       "      <td>AECOM India Private Limited</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Business Analyst: ADM</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>6-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Business Analyst: ADM</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>10-15 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Business Analyst - Operations</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>6-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Business Analyst - Operations</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Business Analyst - Risk Domain (VaR, Expected ...</td>\n",
       "      <td>Oracle India Pvt. Ltd.</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Tech Mahindra Hiring For Business Analyst (KYC...   \n",
       "1  Senior IT Business Analyst/ Requirements Engin...   \n",
       "2                                   Business Analyst   \n",
       "3                                   Business Analyst   \n",
       "4             Regional Applications Business Analyst   \n",
       "5                              Business Analyst: ADM   \n",
       "6                              Business Analyst: ADM   \n",
       "7                      Business Analyst - Operations   \n",
       "8                      Business Analyst - Operations   \n",
       "9  Business Analyst - Risk Domain (VaR, Expected ...   \n",
       "\n",
       "                             company                      location experience  \n",
       "0                  tech mahindra ltd           Bangalore/Bengaluru    5-8 Yrs  \n",
       "1                            Innoveo  Chennai, Bangalore/Bengaluru   6-10 Yrs  \n",
       "2                    Infosys Limited           Bangalore/Bengaluru   5-10 Yrs  \n",
       "3  Flipkart Internet Private Limited           Bangalore/Bengaluru    1-6 Yrs  \n",
       "4        AECOM India Private Limited           Bangalore/Bengaluru   5-10 Yrs  \n",
       "5             IBM India Pvt. Limited           Bangalore/Bengaluru   6-10 Yrs  \n",
       "6             IBM India Pvt. Limited           Bangalore/Bengaluru  10-15 Yrs  \n",
       "7             IBM India Pvt. Limited           Bangalore/Bengaluru   6-10 Yrs  \n",
       "8             IBM India Pvt. Limited           Bangalore/Bengaluru    1-4 Yrs  \n",
       "9             Oracle India Pvt. Ltd.           Bangalore/Bengaluru    3-5 Yrs  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "jobs=pd.DataFrame({})\n",
    "jobs['title']= job_titles[:10]\n",
    "jobs['company']= company_names[:10]\n",
    "jobs['location']= job_locations[:10]\n",
    "jobs['experience']= experience_req[:10]\n",
    "\n",
    "jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, full job-description. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening web driver\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#giving url to webdriver\n",
    "url='https://www.naukri.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#searching xpath on webpage\n",
    "search_job=driver.find_element_by_xpath('//input[@class=\"sugInp\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#giving input in search bar\n",
    "search_job.send_keys(\"data scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#searching xpath on webpage\n",
    "search_loc=driver.find_element_by_id(\"qsb-location-sugg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#giving input in search bar\n",
    "search_loc.send_keys(\"banglore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#searching data and pressing button\n",
    "search_button=driver.find_element_by_xpath('//button[@class=\"btn\"]')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find jobs\n",
    "job_title=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_titles=[]\n",
    "for i in job_title:\n",
    "    job_titles.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find company name\n",
    "com_name=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_names=[]\n",
    "for i in com_name:\n",
    "    company_names.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching job location\n",
    "job_location=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']//span\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_locations=[]\n",
    "for i in job_location:\n",
    "    job_locations.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "url =driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_url=[]\n",
    "for i in url:\n",
    "    job_url.append(i.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Evaluating business requirements and developing compelling user stories in collaboration with business stakeholders across various functions and regions\\nCollecting, interpreting, preparing and modelling data to provide actionable insights\\nPrototyping advanced data analytics solutions for presentation to business partners and stakeholders\\nApplying predictive analytics and machine learning methods and techniques appropriately to address business requirements\\nProvide expertise to guide business stakeholders in identifying opportunities for the use of BD s data assets for the purpose of advanced data analytics\\nWork closely with data engineering and DataOps peers to productionalize advanced data analytics use cases\\nQualifications\\nMaster s degree in STEM field or equivalent demonstrated work experience\\nExperience with Python, R, Hadoop, HIVE, SPARK, Jupyter and related advanced analytics / machine learning libraries (Scikitlearn, Tensorflow, Keras, )\\nMinimum 2 years of relevant work experience\\nAbility to translate complex solutions to a non-technical audience (storytelling visualization)\\nExpertise in machine learning, neural networks, clustering, classification, regression and other common advanced analytics methods and techniques\\nMature competency for critical thinking, problem solving, working with ambiguity, communications and collaboration\\nPreferred\\nExperience with technologies related to data preparation, processing optimization (e.g. Azure, HQL, SPARK SQL)\\nExperience with data visualization tools (Power BI)\\nFlexibility to accommodate meetings with international stakeholders in their respective time-zone',\n",
       " \"Job description\\n\\nJob Role: Data Scientist/Data Analyst /Business Analyst\\n\\nLocation: Chennai/Bangalore/Hyderabad\\n\\nGreetings from CAIA - Center for Artificial Intelligence & Advanced Analytics\\n43% of companies experienced a high deficit of skilled resources with Advanced Analytical skills and AI implementing capabilities in the year 2020. CAIA gives you a great opportunity to enter the world of future technologies and Innovations- Data Science, Analytics, AI, Data Visualization, and Cloud Computing.\\n\\nWhile 2020 was a year like no other, we are living in an interesting times where data is reshaping the world, and businesses are rapidly adopting technology to gain an edge over others. Hence, there's a substantial increase in demand for technology professionals who can implement systems in data science, machine learning, and AI in Tier 1 and Tier 2 organizations working closely with us.\\n\\nTo help you build a sustainable career we would like you to utilize data, software and Analytical approaches in Data Science and AI to upskill and get recruited into an organization appreciating your skilling journey.\\nApplications invited from all Freshers and experienced candidates (0-3 yrs) aspiring to make a career in Artificial Intelligence and Advanced Analytics and Data Science.\\nIf you wish to make a shift in your career or undergo a career transition, upskilling is essential since it allows you to learn more about the domain and acquire the required skills.\\n\\nCall to schedule interview Monday -Saturday from 10:00 am to 7 Pm\\n\\nKoodesh B- +91 73395 11107\\nManigandan B - +91 93444 57360\\n\\nEmail :\\n\\ncareerguidance.koodes@centerforaia.com\\nmanigandan@centerforaia.com\\n\\nWhat is needed from you?\\nFreshers who wish to start their career in Analytics and AI and professionals who wish to\\nupskill or change their domain to analytics and emerging technologies are free to apply.\\nEducational background in any one of the following- BE/B.Tech, ME/M Tech, MSc, BSc/MSc Math's and Statistics, B Com, BCA, BSc CS, BSC IT, MSC IT, MCA\\nSkills relating to Mathematics/Statistics.\\nNatural passion towards numbers, business, coding, Analytics, and Artificial Intelligence, Machine Learning, visualization\\nGood verbal and written communication skills\\nAbility to understand domains in businesses across various sectors\\n\\nSelection procedure includes\\nAptitude Test & Communication Exam - Online / Offline\\nSQL/Python test - Online / Offline\\nCandidates who clear the above will have one-one discussions with our Career Guidance Manager for further evaluation and processing of your Resume.\\n\\nAll the Shortlisted candidates will be eligible to continue the corporate training with CAIA\\nWhat you can expect from us?\\n\\nYou will get trained on the following modules for a period of 12-14 weeks:\\nSQL & PLSQL\\nData Wrangling using Python\\nData Visualization Using Power-BI\\nStatistics for Machine Learning\\nArtificial Intelligence, Data Interpretation\\nSupervised & Unsupervised Learning,\\nNLP & Deep Learning\\nCloud Data Lake\\nBusiness intelligence & Data Visualization\\nSimulation Projects\\nExpected Outcome?\\n\\nAt the end of the Training you are expected to be well versed with the following:\\nAnalysis of large and complex data sets from multiple sources\\nDevelopment and evaluation of data analytics models, algorithms, and solutions\\nUnderstanding/implementation of ML algorithms, performance tuning, and reporting\\nImplementation of algorithms to mine targeted data and the ability to convert data into a business story\\nTranslation of business requirements into technical requirements; Data extraction, preparation, and transformation\\nIdentification, development, and implementation of statistical techniques and algorithms that address business challenges and adds value to the organization\\nRequirement Analysis and communication of findings in the form of a meaningful story with the stakeholders\\nFinding analytical solutions to abstract business issues.\\nApply objective analysis of facts before coming to a conclusion\",\n",
       " 'About the team\\nThe Data Sciences team at Flipkart is on a mission to build systemic intelligence across Flipkart products and the overarching ecosystem. Being India’s largest online marketplace and the most used e-commerce app in India, places Flipkart in a unique position and gives this team a distinctive opportunity — to decipher the richest possible data about Indian consumers. Add the dimension of a vast product selection and a proliferating seller base to that and what you get is a multitude of disruptive possibilities.\\nIn a nutshell, the terabytes of daily data compounded in Flipkart’s data centres offer a dynamic mix of numerical, structured, unstructured, image- and audio-based statistics, all set to define shopping in the future.\\nAt Flipkart, the work of a Data Scientist involves collaboration with the engineering and product teams to ensure a holistic outcome at the product delivery. The flat functional structure within Flipkart engineering enables data scientists to focus on excellence and create a deep sense of ownership at every stage of work.\\nIf you aspire to redefine ‘state-of-the-art’ and create an impact on India’s online shopping landscape, Flipkart’s Data Science team can offer you the right podium to solve challenging real-world problems and take a giant leap in your career as a Data Scientist.\\nAbout the role\\nA Data Scientist in Flipkart is required to develop and implement ML or statistical models for the various projects formulated from business and product views. The responsible person should be able to communicate and collaborate with multiple stakeholders representing various teams to better understand the problem at hand. At a fundamental level, the responsible person should be able to dive deep into a problem statement and extract interesting insights as well as solutions. In addition to being a quick learner, a DS is expected to get involved in active research projects with a view to publish them.\\nWhat you’ll do\\nUnderstand Business and product needs and use ML or statistical techniques to provide solutions to those in a time bound fashion.\\nCommunicate and collaborate with business and product teams to have a better understanding of the project so as to be able to drive it within the DS team.\\nGet involved in in-depth exploration of solutions using various methods and extract statistical insights from data as well as models, which are to be shared with business and product teams.\\nActive participation in working with new methods and learning new technologies, both in the area of data science and data engineering.\\nWhat you’ll need:\\nB.Tech or M.Tech in CS or Statistics with experience ranging from 0 to 5 years through publications/deployed solutions/projects.\\nDeep understanding of the algorithms (theory and application) that they have worked on.\\nGood grasp on the theory and practise of basic statistical models such as regression or clustering and general ML algorithms such as tree, Random Forests, SVM, Boosting, Neural Networks etc. It is not expected that the candidate has actually worked on all these modules.\\nStrong proficiency in Python or R is necessary.\\nSkills Required :\\nUnderstanding of text representation techniques\\nDesirable Skills :\\nFamiliarity with Big Data frameworks – Spark, Hadoop',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " 'About the Role\\n  They say no man is an island - a notion that holds particularly true for this role. As a Data Scientist, you ll be an instrumental cog in the Marketplace wheel of Gojek that directly impacts GoFoods revenue and user experience.\\n   Your main objective will be to utilize various quantitative techniques such as Machine Learning, Optimization, Simulation, and Bayesian Techniques to drive asymmetric values for our business at Gojek. The folks over at the Data Science Platform team will be your companions during this ride, as they help to bring your models to production. Best yet, you ll have the opportunity to flex and hone in on your skills in ideation, research, and building prototypes!\\n  What You Will Do\\nDesign and develop various machine learning solutions for improving search relevance\\nOwn the Data Science model end-to-end from data collection to model building to monitoring the model in production\\nAlong with Product Managers, own the business outcomes/metrics which the data science model/algorithm drives\\nIdentify ways to better leverage our content and improve its quality and attributes, to improve the overall search experience\\nWhat You Will Need\\nAt least 5 years of experience in building machine learning models for product applications\\nMust have the ability to understand business concerns and formulate them as technical problems that can be solved using data and math/stats/ML\\nFamiliarity with essential data science libraries, including Pandas, Numpy, Scipy, Scikit-Learn\\nExperience building scalable ML solutions to NLP problems\\nFamiliarity with ML infrastructure needs and best practices\\nExperience working with cross-functional teams including product, design, engineering, mobile to deliver product outcomes using data science\\n ',\n",
       " '  About the Role\\n  They say no man is an island - a notion that holds particularly true for this role. As a Data Scientist, you ll be an instrumental cog in the Marketplace wheel of Gojek that directly impacts GoFoods revenue and user experience. Your main objective will be to utilize various quantitative techniques such as Machine Learning, Optimization, Simulation, and Bayesian Techniques to drive asymmetric values for our business at Gojek.\\n   The folks over at the Data Science Platform team will be your companions during this ride, as they help to bring your models to production. Best yet, you ll have the opportunity to flex and hone in on your skills in ideation, research, and building prototypes!\\n  What You Will Do\\nDesign and develop various machine learning solutions for improving search relevance\\nOwn the Data Science model end-to-end from data collection to model building to monitoring the model in production\\nAlong with Product Managers, own the business outcomes/metrics which the data science model/algorithm drives\\nIdentify ways to better leverage our content and improve its quality and attributes, to improve the overall search experience\\nWhat You Will Need\\nAt least 5 years of experience in building machine learning models for product applications\\nMust have the ability to understand business concerns and formulate them as technical problems that can be solved using data and math/stats/ML\\nFamiliarity with essential data science libraries, including Pandas, Numpy, Scipy, Scikit-Learn\\nExperience building scalable ML solutions to NLP problems\\nFamiliarity with ML infrastructure needs and best practices\\nExperience working with cross-functional teams including product, design, engineering, mobile to deliver product outcomes using data science',\n",
       " 'A consistent record of using product data to drive product, sales, and/or marketing teams to achieve ambitious goals and influencing outcomes.\\nThe ability to clearly and effectively communicate the results of complex analysis to a broad audience Expertise in at least one programming language for data analysis (e.g.Python, R).\\nExpertise in designing and testing experiments.\\nExperience working with data technologies that allow effective storage and analysis of large amounts of data (e.g. Hadoop, Hive, Spark, Presto, S3, etc).\\n\\nAn advanced degree in Computer Science (or allied field) from a top-tier institute (Preferred).\\n4+ years of experience of which 2+ in data - pipelining, modeling, and\\nlearning\\n\\nDemonstrated hands-on experience developing and building learning models for data at scale Solid understanding of data pipelining, extraction, and cleanup Strong familiarity with information extraction and applicability of various learning models (supervised and unsupervised) is required The candidate will work directly with the senior leadership team and will have an opportunity to do ground-breaking work in healthcare.\\nDesired Skills - Machine learning, Python, sql, keras, NLP and understanding of different model architectures\\n\\nThis is a very creative role. candidate is expected to have demonstrated competitive skills in ML/AI via winning Kaggle or Chalearn competitions. Candidate is expected to contribute to IP and patents with innovation in automatic model generation and various algorithms like NAS, meta-learning, transfer learning, and model monitoring.\\n\\nWorking knowledge and hands-on implementation experience of CRISP-DM model\\n\\nKnowledge of google automl , IBM autoAI, H20, Scikit learn, autokeras\\n\\nExperience in designing data interfaces\\n\\nTo work with customers to critical AI deployment problems and solve with innovation To own the complete project plan',\n",
       " '-',\n",
       " '-',\n",
       " 'Skillsets:\\n\\nMinimum 5years of experience.\\n\\nPrimary Skillsets:\\n\\n- Hands-on experience with Machine Learning, Python, Hadoop Querying\\n\\n- Needs to have proven record of performing data mining / building machine learning solutions.\\n\\n- Knowledge in statistics will be preferred.\\n\\n- Good understanding in ML algorithms and their usage\\n\\n- Machine Learning /Deep Learning, SQL, Tableau\\n\\nNotice period - 30days max',\n",
       " 'We are looking for outstanding Data Scientist for a $150Million, Series C funded Fintech company Headquartered in Bangalore.\\n\\nResponsibilities:\\n\\n- Ensure that data flows smoothly from source to destination so that it can be processed\\n\\n- Utilize strong database skills to work with large, complex data sets to extract insights\\n\\n- Filter and cleanse unstructured (or ambiguous) data into usable data sets that can be analyzed to extract insights and improve business processes\\n\\n- Identify new internal and external data sources to support analytics initiatives and work with appropriate partners to absorb the data into new or existing data infrastructure\\n\\n- Build tools for automating repetitive asks so that bandwidth can be freed for analytics\\n\\n- Collaborate with program managers and business analysts to help them come up with actionable, high-impact insights across product lines and functions\\n\\n- Work closely with top management to prioritize information and analytic needs\\n\\nRequirements:\\n\\n- Bachelors or Masters in a quantitative field (such as Engineering, Statistics, Math, Economics, or Computer Science with Modeling/ Data Science), preferably with work experience of over 4 years.\\n\\n- Ability to program in any high level language is required. Familiarity with R and statistical packages are preferred.\\n\\n- Proven problem solving and debugging skills.\\n\\n- Familiar with database technologies and tools (SQL/R/SAS/JMP etc.), data warehousing, transformation and processing. Work experience with real data for customer insights, business and market analysis will be advantageous.\\n\\n- Experience with text analytics, data mining and social media analytics.\\n\\n- Statistical knowledge in standard techniques: Logistic Regression, Classification models, Cluster Analysis, Neural Networks, Random Forests, Ensembles, etc.\\n\\nSkills - PYTHON, R, SQL, DATA SCIENCE, DATA ANALYTICS',\n",
       " 'Brief about the Role\\nThe Platforms team of the Data Science Group at [24]7.ai builds scalable AI to aid in conversational AI, agent assist solutions, and ad personalization for the Cloud. We are looking for a highly motivated and qualified data scientist to build some of our AI initiatives. This role is ideal for candidates with strong, hands-on skills in machine learning and natural language processing.\\nEducational Qualifications:\\nBachelors, Master’s or PhD degree from reputed universities or institutes in one of the following disciplines:\\nArtificial Intelligence / Machine Learning\\nData Science\\nCognitive Computing\\nComputational Linguistics\\nComputer Science\\nRequirements\\n4+ years of experience with general purpose programming languages e.g., Python, C/C++, Java\\n4+ years of hands-on experience in machine learning\\nExperience in various deep learning models, e.g., transformers, LSTMs, RNNs\\nExperience in solving problems related to Natural Language Processing (NLP), Natural Language Understanding (NLU), and Natural Language Generation (NLG)\\nExperience with machine learning platforms such as TensorFlow, TensorFlow Extended, PyTorch\\nExperience building and deploying machine learning models on the Cloud (Google Cloud, Azure, AWS)\\nExperience with production architecture of machine learning systems\\nGood to have exposure to conversational AI, AI-based question-answering systems, AI-based compliance and monitoring systems, and ad personalization\\nGood to have exposure to MLOps pipelines and Kubeflow\\nExcellent communication skills\\nAbility to collaborate cross-functionally\\nGood presentation skills\\nAttention to detail\\nResponsibilities\\nCollaborate with the Engineering and Product teams to implement machine learning models into the products and offerings of [24]7.ai\\nCollaborate with your team members. Be responsible for implementing the machine learning models, testing them, refining them, and taking them to production\\nCollaborate within the Data Science Group to review and refine your work to ensure the highest quality\\nTake end-to-end ownership of AI initiatives\\nProactively discuss ideas for feature enhancements with the data science leadership and product leadership',\n",
       " 'Minimum Qualifications: (Specify if degree required & type, number of years of prior experience, certifications, etc.)\\nPost Graduate or MBA (preferred) OR Graduates in Engineering / Mathematics / Operations Research / Science / Statistics\\nWith atleast 5+ years experience in analytics using SQL,SAS, R or Python, basic statistical concepts and analyzing data & interpreting results to the business\\n\\n\\nProficient in data wrangling using SQL and libraries of R,Python such as Dplyr/Pandas, Pyspark etc\\nProficient in basic statistical concepts and analyzing data & interpreting results to the business\\nApplied Machine learning experience or experience in text mining, imaging mining, screen scraping and other big data techniques will be a plus\\nResponsibilities and Essential Functions:\\nAnalytics Practice within SCIO:\\nAbility to design data driven solutions and Frameworks (Descriptive and Predictive) from scratch & consult in a leadership capacity on potential Solutions/Storyboards and POCs\\nDrives business metrics that add to the top-line and / or profitability for SCIOs revenue optimization business\\nPerform quantitative and qualitative analysis like (raw) data analysis, statistical modeling, data deep-dives etc. to acquire insights from data\\nDevelops Descriptive (reporting) through to Prescriptive Analytics\\nTranslates insights into an analysis reports and communicate insights back to the stakeholders\\nApplies next-gen technology to all parts of the analytics lifecycle from data extraction, exploratory data analysis, predictive modeling, Data Mining and information extraction from unstructured data to visualization & story boarding\\nSpecial Skills and Qualifications:\\nThis role would suit candidates with the following attributes:\\nFlexibility to work with different countries (time-zones), groups, and business environment\\nShould be versatile and ready to learn and apply new technologies, techniques in data science\\nAbility to break down a vague business problem into structured data analysis approaches\\nAbility to work with incomplete information and take judgment-driven decisions based on experience\\nShould have good organizational and people skills\\nShould have good communication able to collaborate with onshore stakeholders\\nStrong aptitude to learn/understand health care data / databases',\n",
       " 'Key Responsibilities:\\nProvide advanced analytical capabilities to support and drive data science initiatives\\nMines and extracts data and apply statistics and algorithms necessary to derive insights for Org s Digital\\nSupports the generation of an automated insights generation framework for Org s business partners to effectively interpret data\\nProvides actionable insights through data science for Recommendations, SEO and Collections selling\\nWork closely with the product and engineering teams to execute key initiatives\\nTracks success of Org s through the development of dashboard reports that measure financial results, customer satisfaction, and engagement metrics\\nConducts deep statistical analysis, including predictive and prescriptive modeling in order to provide a competitive advantage at Org s\\nMaintains expert-level knowledge on industry trends, emerging technologies, and new methodologies and applies it to projects as well as using it to guide team members\\nLeads automation and analytical projects, collaborating across functions in Org s and Org s Digital\\nJob Requirements\\nRequired Skills:\\nIndustry experience as a Data Scientist and experience in machine learning, data mining, search relevancy ranking, recommender systems or informational retrieval.\\nHands-on experience with accessing data, Python, machine learning libraries, and deep learning libraries (ex: tensorflow/pytorch/Keras, scikit-learn/scipi, numpy, pandas, Golve, word2vec, fasttext, bert etc.).\\nAbility to improve product discovery by collaborating with other domain teams such as Personalization and Search\\nFluency in at-least one programming languages such as Python, Scala or Java.\\nPresent results and make recommendations in a clear manner to senior leadership\\nAbility to learn new analytical methods and technologies and apply in practical business problems\\nStrong communication skills, ability to interact with diverse team of people across business and engineering.\\nEffective analytical, troubleshooting and problem-solving skills for building systems to process both structured and unstructured data\\n ',\n",
       " 'As as Senior Data Scientist, you will work in teams addressing statistical, machine learning and data understanding problems in a commercial technology and consultancy development environment. In this role, you will contribute to the development and deployment of modern machine learning, operational research, semantic analysis, and statistical methods for finding structure in large data sets.\\nAs a Sr Data Scientist, you will be responsible for:\\nDesigning and develop machine learning algorithms, software utilities, tools, data sets, and experiments to build AI models.\\nBuilding solutions and delivering code from proof of concept to production-level maturity following agile development principles.\\nBreaking down and understanding complex business problems, defining a solution, and implementing it using advanced quantitative methods.\\nKeeping up to date with state-of-the-art machine learning literature and industry best practices for large-scale robust algorithm development.\\nDocumenting developments and results as needed for documentation, publications, patent submissions, and internal or external presentations.\\nCollaborating with cross-functional teams across multiple offices and regions. Also, Work alongside software developers and software engineers to translate algorithms into commercially viable products and services.\\nUnit-Testing for production quality code development and supporting end-to-end testing of delivered software components.\\nWorking in technical teams in development, deployment, and application of applied analytics, predictive analytics, and prescriptive analytics.\\nFuel your passion, To be successful in this role you will:\\nHave bachelors in Computer Science or STEM Majors (Science, Technology, Engineering and Math). A minimum 4 yrs of professional experience.\\nHave knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests, and proper usage, etc.) and experience with applications.\\nExperience in Machine Learning/AI techniques including Deep learning (RNN, CNN, GAN, etc.), Support Vector Machines; Regularization Techniques; Boosting, Random Forests, Ensemble Methods, image/video/audio processing, Bayesian statistics, and time series modelling.\\nHave extensive applied experience with Reinforcement Learning is desired.\\nHave experience in developing and deploying machine learning solutions in cloud environments like AWS, Azure, and GCP.\\nHave developed containerized solutions (Docker, Mesos, etc.).\\nHave solid programming skills for data sciences and numerical computing: Python, R, and SQL and ability to work with a variety of deep learning frameworks including TensorFlow, Keras, Caffe, etc.\\nHave hands-on skills in sourcing, manipulating, and analysing large volumes of data including SQL and NoSQL databases.',\n",
       " 'As as Senior Data Scientist, you will work in teams addressing statistical, machine learning and data understanding problems in a commercial technology and consultancy development environment. In this role, you will contribute to the development and deployment of modern machine learning, operational research, semantic analysis, and statistical methods for finding structure in large data sets.\\nAs a Sr Data Scientist, you will be responsible for:\\nDesigning and develop machine learning algorithms, software utilities, tools, data sets, and experiments to build AI models.\\nBuilding solutions and delivering code from proof of concept to production-level maturity following agile development principles.\\nBreaking down and understanding complex business problems, defining a solution, and implementing it using advanced quantitative methods.\\nKeeping up to date with state-of-the-art machine learning literature and industry best practices for large-scale robust algorithm development.\\nDocumenting developments and results as needed for documentation, publications, patent submissions, and internal or external presentations.\\nCollaborating with cross-functional teams across multiple offices and regions. Also, Work alongside software developers and software engineers to translate algorithms into commercially viable products and services.\\nUnit-Testing for production quality code development and supporting end-to-end testing of delivered software components.\\nWorking in technical teams in development, deployment, and application of applied analytics, predictive analytics, and prescriptive analytics.\\nFuel your passion, To be successful in this role you will:\\nHave bachelors in Computer Science or STEM Majors (Science, Technology, Engineering and Math). A minimum 4 yrs of professional experience.\\nHave knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests, and proper usage, etc.) and experience with applications.\\nExperience in Machine Learning/AI techniques including Deep learning (RNN, CNN, GAN, etc.), Support Vector Machines; Regularization Techniques; Boosting, Random Forests, Ensemble Methods, image/video/audio processing, Bayesian statistics, and time series modelling.\\nHave extensive applied experience with Reinforcement Learning is desired.\\nHave experience in developing and deploying machine learning solutions in cloud environments like AWS, Azure, and GCP.\\nHave developed containerized solutions (Docker, Mesos, etc.).\\nHave solid programming skills for data sciences and numerical computing: Python, R, and SQL and ability to work with a variety of deep learning frameworks including TensorFlow, Keras, Caffe, etc.\\nHave hands-on skills in sourcing, manipulating, and analysing large volumes of data including SQL and NoSQL databases.',\n",
       " 'As as Senior Data Scientist, you will work in teams addressing statistical, machine learning and data understanding problems in a commercial technology and consultancy development environment. In this role, you will contribute to the development and deployment of modern machine learning, operational research, semantic analysis, and statistical methods for finding structure in large data sets.\\nAs a Sr Data Scientist, you will be responsible for:\\nDesigning and develop machine learning algorithms, software utilities, tools, data sets, and experiments to build AI models.\\nBuilding solutions and delivering code from proof of concept to production-level maturity following agile development principles.\\nBreaking down and understanding complex business problems, defining a solution, and implementing it using advanced quantitative methods.\\nKeeping up to date with state-of-the-art machine learning literature and industry best practices for large-scale robust algorithm development.\\nDocumenting developments and results as needed for documentation, publications, patent submissions, and internal or external presentations.\\nCollaborating with cross-functional teams across multiple offices and regions. Also, Work alongside software developers and software engineers to translate algorithms into commercially viable products and services.\\nUnit-Testing for production quality code development and supporting end-to-end testing of delivered software components.\\nWorking in technical teams in development, deployment, and application of applied analytics, predictive analytics, and prescriptive analytics.\\nFuel your passion, To be successful in this role you will:\\nHave bachelors in Computer Science or STEM Majors (Science, Technology, Engineering and Math). A minimum 4 yrs of professional experience.\\nHave knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests, and proper usage, etc.) and experience with applications.\\nExperience in Machine Learning/AI techniques including Deep learning (RNN, CNN, GAN, etc.), Support Vector Machines; Regularization Techniques; Boosting, Random Forests, Ensemble Methods, image/video/audio processing, Bayesian statistics, and time series modelling.\\nHave extensive applied experience with Reinforcement Learning is desired.\\nHave experience in developing and deploying machine learning solutions in cloud environments like AWS, Azure, and GCP.\\nHave developed containerized solutions (Docker, Mesos, etc.).\\nHave solid programming skills for data sciences and numerical computing: Python, R, and SQL and ability to work with a variety of deep learning frameworks including TensorFlow, Keras, Caffe, etc.\\nHave hands-on skills in sourcing, manipulating, and analysing large volumes of data including SQL and NoSQL databases.']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_description=[]\n",
    "for i in job_url:\n",
    "    driver.get(i)\n",
    "    try:\n",
    "        job_desc = driver.find_element_by_xpath(\"//div[@class='dang-inner-html']\")\n",
    "        job_description.append(job_desc.text)\n",
    "    except:\n",
    "        job_description.append('-')\n",
    "job_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>bd</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Evaluating business requirements and developin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist / Data Analyst -Business Analyst</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>Hyderabad/Secunderabad, Chennai, Bangalore/Ben...</td>\n",
       "      <td>Job description\\n\\nJob Role: Data Scientist/Da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Flipkart Internet Private Limited</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>About the team\\nThe Data Sciences team at Flip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Oracle India Pvt. Ltd.</td>\n",
       "      <td>Noida, Bangalore/Bengaluru</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist: Advanced Analytics</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>inVentiv International Pharma Services Pvt. Ltd.</td>\n",
       "      <td>Hyderabad/Secunderabad, Gurgaon/Gurugram, Bang...</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Applied Materials</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist 2</td>\n",
       "      <td>Gojek Tech</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>About the Role\\n  They say no man is an island...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist 2</td>\n",
       "      <td>GO-JEK India</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>About the Role\\n  They say no man is an isla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hiring Data Scientist</td>\n",
       "      <td>IHX private limited</td>\n",
       "      <td>Bangalore/Bengaluru(5th block Koramangala)</td>\n",
       "      <td>A consistent record of using product data to d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             title  \\\n",
       "0                              Lead Data Scientist   \n",
       "1  Data Scientist / Data Analyst -Business Analyst   \n",
       "2                                   Data Scientist   \n",
       "3                                   Data Scientist   \n",
       "4               Data Scientist: Advanced Analytics   \n",
       "5                            Senior Data Scientist   \n",
       "6                                   Data Scientist   \n",
       "7                                 Data Scientist 2   \n",
       "8                                 Data Scientist 2   \n",
       "9                            Hiring Data Scientist   \n",
       "\n",
       "                                            company  \\\n",
       "0                                                bd   \n",
       "1                Inflexion Analytix Private Limited   \n",
       "2                 Flipkart Internet Private Limited   \n",
       "3                            Oracle India Pvt. Ltd.   \n",
       "4                            IBM India Pvt. Limited   \n",
       "5  inVentiv International Pharma Services Pvt. Ltd.   \n",
       "6                                 Applied Materials   \n",
       "7                                        Gojek Tech   \n",
       "8                                      GO-JEK India   \n",
       "9                               IHX private limited   \n",
       "\n",
       "                                            location  \\\n",
       "0                                Bangalore/Bengaluru   \n",
       "1  Hyderabad/Secunderabad, Chennai, Bangalore/Ben...   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3                         Noida, Bangalore/Bengaluru   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5  Hyderabad/Secunderabad, Gurgaon/Gurugram, Bang...   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9         Bangalore/Bengaluru(5th block Koramangala)   \n",
       "\n",
       "                                         description  \n",
       "0  Evaluating business requirements and developin...  \n",
       "1  Job description\\n\\nJob Role: Data Scientist/Da...  \n",
       "2  About the team\\nThe Data Sciences team at Flip...  \n",
       "3                                                  -  \n",
       "4                                                  -  \n",
       "5                                                  -  \n",
       "6                                                  -  \n",
       "7  About the Role\\n  They say no man is an island...  \n",
       "8    About the Role\\n  They say no man is an isla...  \n",
       "9  A consistent record of using product data to d...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "jobs=pd.DataFrame({})\n",
    "jobs['title']= job_titles[:10]\n",
    "jobs['company']= company_names[:10]\n",
    "jobs['location']= job_locations[:10]\n",
    "jobs['description']= job_description[:10]\n",
    "\n",
    "jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3: In this question you have to scrape data using the filters:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to use the location and salary filter.                                                                                 \n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.                                              \n",
    "You have to scrape the job-title, job-location, company_name, experience_required.\n",
    "The location filter to be used is “Delhi/NCR”                                                                                   \n",
    "The salary filter to be used is “3-6” lakhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening web driver\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#giving url to webdriver\n",
    "url='https://www.naukri.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"50ac55a97f614495d5151c8ce4bb4a48\", element=\"8f0a1228-c96c-4c84-a0f3-387d2bc5a681\")>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#searching xpath on webpage\n",
    "search_job=driver.find_element_by_xpath('//input[@class=\"sugInp\"]')\n",
    "search_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#giving input in search bar\n",
    "search_job.send_keys(\"data scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#searching data and pressing button\n",
    "search_button=driver.find_element_by_xpath('//button[@class=\"btn\"]')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using filter for location\n",
    "location_filter=driver.find_element_by_xpath('/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[3]/div[2]/div[3]/label/p/span[1]')\n",
    "location_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set salary range using filter\n",
    "salary_filter=driver.find_element_by_xpath(\"/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[4]/div[2]/div[2]\")\n",
    "salary_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist/Data Analyst /Business Analyst',\n",
       " 'Senior Data Scientist',\n",
       " 'Team Leader Operations/Data Scientist',\n",
       " 'Only Fresher / Data Scientist / Data Analyst / Analytics - MNC Jobs',\n",
       " 'Data Scientist (Early Joiner)',\n",
       " 'Data Scientist - Machine Learning/ NLP',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist || Python || C2H',\n",
       " 'Data Scientist || Python || C2H',\n",
       " 'Advanced Analytics -Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist -Delhi',\n",
       " 'Senior Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Associate Data Scientist',\n",
       " 'Associate Data Scientist',\n",
       " 'DATA SCIENTIST']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find jobs\n",
    "job_title=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "job_titles=[]\n",
    "for i in job_title:\n",
    "    job_titles.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find company name\n",
    "com_name=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "company_names=[]\n",
    "for i in com_name:\n",
    "    company_names.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find job location\n",
    "job_location=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "job_locations=[]\n",
    "for i in job_location:\n",
    "    job_locations.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "experience=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']\")\n",
    "experience_req=[]\n",
    "for i in experience:\n",
    "    experience_req.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist/Data Analyst /Business Analyst</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>Pune, Delhi / NCR, Mumbai (All Areas)</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>inVentiv International Pharma Services Pvt. Ltd.</td>\n",
       "      <td>Hyderabad/Secunderabad, Gurgaon/Gurugram, Bang...</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Team Leader Operations/Data Scientist</td>\n",
       "      <td>Optimint Solutions Pvt. Ltd.</td>\n",
       "      <td>Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Only Fresher / Data Scientist / Data Analyst /...</td>\n",
       "      <td>GABA Consultancy services</td>\n",
       "      <td>Noida, Greater Noida, Delhi / NCR</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist (Early Joiner)</td>\n",
       "      <td>R Systems International Ltd.</td>\n",
       "      <td>Noida(Sector-59 Noida)</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist - Machine Learning/ NLP</td>\n",
       "      <td>TalPro</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>recruitment advisory line</td>\n",
       "      <td>Hyderabad/Secunderabad, Gurgaon/Gurugram, Bang...</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist || Python || C2H</td>\n",
       "      <td>Growel Softech Pvt. Ltd.</td>\n",
       "      <td>Noida, Kolkata, Gurgaon/Gurugram, Bangalore/Be...</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist || Python || C2H</td>\n",
       "      <td>Growel Softech Pvt. Ltd.</td>\n",
       "      <td>Noida, Kolkata, Gurgaon/Gurugram, Bangalore/Be...</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Advanced Analytics -Data Scientist</td>\n",
       "      <td>ERM Placement Services (P) Ltd.</td>\n",
       "      <td>New Delhi, Hyderabad/Secunderabad</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0      Data Scientist/Data Analyst /Business Analyst   \n",
       "1                              Senior Data Scientist   \n",
       "2              Team Leader Operations/Data Scientist   \n",
       "3  Only Fresher / Data Scientist / Data Analyst /...   \n",
       "4                      Data Scientist (Early Joiner)   \n",
       "5             Data Scientist - Machine Learning/ NLP   \n",
       "6                                     Data Scientist   \n",
       "7                    Data Scientist || Python || C2H   \n",
       "8                    Data Scientist || Python || C2H   \n",
       "9                 Advanced Analytics -Data Scientist   \n",
       "\n",
       "                                            company  \\\n",
       "0                Inflexion Analytix Private Limited   \n",
       "1  inVentiv International Pharma Services Pvt. Ltd.   \n",
       "2                      Optimint Solutions Pvt. Ltd.   \n",
       "3                         GABA Consultancy services   \n",
       "4                      R Systems International Ltd.   \n",
       "5                                            TalPro   \n",
       "6                         recruitment advisory line   \n",
       "7                          Growel Softech Pvt. Ltd.   \n",
       "8                          Growel Softech Pvt. Ltd.   \n",
       "9                   ERM Placement Services (P) Ltd.   \n",
       "\n",
       "                                            location experience  \n",
       "0              Pune, Delhi / NCR, Mumbai (All Areas)    0-3 Yrs  \n",
       "1  Hyderabad/Secunderabad, Gurgaon/Gurugram, Bang...    3-6 Yrs  \n",
       "2                      Gurgaon/Gurugram, Delhi / NCR    2-5 Yrs  \n",
       "3                  Noida, Greater Noida, Delhi / NCR    0-0 Yrs  \n",
       "4                             Noida(Sector-59 Noida)    4-8 Yrs  \n",
       "5                                   Gurgaon/Gurugram    2-6 Yrs  \n",
       "6  Hyderabad/Secunderabad, Gurgaon/Gurugram, Bang...    3-6 Yrs  \n",
       "7  Noida, Kolkata, Gurgaon/Gurugram, Bangalore/Be...    4-6 Yrs  \n",
       "8  Noida, Kolkata, Gurgaon/Gurugram, Bangalore/Be...    4-6 Yrs  \n",
       "9                  New Delhi, Hyderabad/Secunderabad    3-7 Yrs  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs=pd.DataFrame({})\n",
    "jobs['title']= job_titles[:10]\n",
    "jobs['company']= company_names[:10]\n",
    "jobs['location']= job_locations[:10]\n",
    "jobs['experience']= experience_req[:10]\n",
    "\n",
    "jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4: Write a python program to scrape data for first 10 job results for Data scientist Designation in Noida location. You have to scrape company_name, No. of days ago when job was posted, Rating of the company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening web driver\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#giving url to webdriver\n",
    "url='https://www.glassdoor.co.in/Salaries/index.htm'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#searching xpath on webpage\n",
    "search_job=driver.find_element_by_xpath('//input[@class=\"keyword\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#giving input in search bar\n",
    "search_job.send_keys(\"data scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#searching location using id on webpage\n",
    "search_loc=driver.find_element_by_id(\"LocationSearch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#giving input in search bar\n",
    "search_loc.send_keys(\"noida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#searching data and pressing button\n",
    "search_button=driver.find_element_by_xpath('//button[@class=\"gd-btn-mkt\"]')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HR Data Analyst - New Delhi, IN',\n",
       " 'Data Engineer - Python with Azure ADF',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Assistant Manager - Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Analyst - Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'data scientist']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find job titles\n",
    "job_title=driver.find_elements_by_xpath(\"//a[@class='jobLink css-1rd3saf eigr9kq2']\")\n",
    "job_titles=[]\n",
    "for i in job_title:\n",
    "    job_titles.append(i.text)\n",
    "job_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find company name\n",
    "com_name=driver.find_elements_by_xpath(\"//div[@class='d-flex justify-content-between align-items-start']\")\n",
    "company_names=[]\n",
    "for i in com_name:\n",
    "    company_names.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2d',\n",
       " '13d',\n",
       " '6d',\n",
       " '26d',\n",
       " '11d',\n",
       " '4d',\n",
       " '23d',\n",
       " '19d',\n",
       " '8d',\n",
       " '3d',\n",
       " '10d',\n",
       " '26d',\n",
       " '10d',\n",
       " '17d',\n",
       " '5d',\n",
       " '21d',\n",
       " '25d',\n",
       " '16d',\n",
       " '16d',\n",
       " '10d',\n",
       " '24d',\n",
       " '10d',\n",
       " '5d',\n",
       " '1d',\n",
       " '4d',\n",
       " '4d',\n",
       " '24d',\n",
       " '26d',\n",
       " '6d',\n",
       " '10d',\n",
       " '19d',\n",
       " '6d']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find the days before job was posted\n",
    "no_of_days=driver.find_elements_by_xpath(\"//div[@class='d-flex align-items-end pl-std css-mi55ob']\")\n",
    "job_posted_before=[]\n",
    "for i in no_of_days:\n",
    "    job_posted_before.append(i.text)\n",
    "job_posted_before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4.0',\n",
       " '4.0',\n",
       " '4.1',\n",
       " '4.0',\n",
       " '3.8',\n",
       " '3.5',\n",
       " '4.1',\n",
       " '3.9',\n",
       " '4.2',\n",
       " '3.7',\n",
       " '3.1',\n",
       " '3.0',\n",
       " '5.0',\n",
       " '3.8',\n",
       " '3.8',\n",
       " '4.3',\n",
       " '3.8',\n",
       " '4.7',\n",
       " '4.0',\n",
       " '3.8',\n",
       " '4.3',\n",
       " '4.1',\n",
       " '4.1',\n",
       " '4.0',\n",
       " '4.0',\n",
       " '3.9']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find the rating of the company\n",
    "company_rating=[]\n",
    "rating=driver.find_elements_by_xpath(\"//span[@class='css-19pjha7 e1cjmv6j1']\")\n",
    "\n",
    "for i in rating:\n",
    "    try:\n",
    "        company_rating.append(i.text)\n",
    "    except:\n",
    "        company_rating.append('-')\n",
    "company_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>days before posting</th>\n",
       "      <th>ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HR Data Analyst - New Delhi, IN</td>\n",
       "      <td>Bechtel</td>\n",
       "      <td>2d</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Engineer - Python with Azure ADF</td>\n",
       "      <td>Bechtel</td>\n",
       "      <td>13d</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Ericsson</td>\n",
       "      <td>6d</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>MobiKwik</td>\n",
       "      <td>26d</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Crowe</td>\n",
       "      <td>11d</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Lantern Digital Services</td>\n",
       "      <td>4d</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Siemens Technology and Services Private Limited</td>\n",
       "      <td>23d</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Biz2Credit Inc</td>\n",
       "      <td>19d</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Novo</td>\n",
       "      <td>8d</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Ally wiredsoft solutions (P) ltd</td>\n",
       "      <td>3d</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   title  \\\n",
       "0        HR Data Analyst - New Delhi, IN   \n",
       "1  Data Engineer - Python with Azure ADF   \n",
       "2                         Data Scientist   \n",
       "3                         Data Scientist   \n",
       "4                         Data Scientist   \n",
       "5                         Data Scientist   \n",
       "6                         Data Scientist   \n",
       "7                         Data Scientist   \n",
       "8                         Data Scientist   \n",
       "9                         Data Scientist   \n",
       "\n",
       "                                           company days before posting ratings  \n",
       "0                                          Bechtel                  2d     4.0  \n",
       "1                                          Bechtel                 13d     4.0  \n",
       "2                                         Ericsson                  6d     4.1  \n",
       "3                                         MobiKwik                 26d     4.0  \n",
       "4                                            Crowe                 11d     3.8  \n",
       "5                         Lantern Digital Services                  4d     3.5  \n",
       "6  Siemens Technology and Services Private Limited                 23d     4.1  \n",
       "7                                   Biz2Credit Inc                 19d     3.9  \n",
       "8                                             Novo                  8d     4.2  \n",
       "9                 Ally wiredsoft solutions (P) ltd                  3d     3.7  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "jobs=pd.DataFrame({})\n",
    "jobs['title']= job_titles[:10]\n",
    "jobs['company']= company_names[:10]\n",
    "jobs['days before posting']= job_posted_before[:10]\n",
    "jobs['ratings']= company_rating[:10]\n",
    "\n",
    "jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5: Write a python program to scrape the salary data for Data Scientist designation in Noida location.You have to scrape Company name, Number of salaries, Average salary, Min salary, Max Salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activating the chrome browser\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(1)\n",
    "\n",
    "# Opening the homepage of glassdoor\n",
    "url = \" https://www.glassdoor.co.in/Salaries/index.htm\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#job search bar\n",
    "search_job=driver.find_element_by_xpath(\"//input[@class='keyword']\")  \n",
    "search_job.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#location search bar\n",
    "location=driver.find_element_by_xpath(\"//input[@class='loc']\")  \n",
    "location.send_keys(\"Noida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button = driver.find_element_by_xpath(\"//button[@class='gd-btn-mkt']\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find company name\n",
    "com_name=driver.find_elements_by_xpath(\"//a[@class='css-f3vw95 e1aj7ssy3']\")\n",
    "company_names=[]\n",
    "for i in com_name:\n",
    "    company_names.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the minimum salary\n",
    "min_salaries=driver.find_elements_by_xpath(\"//div[@class='d-flex mt-xxsm css-79elbk epuxyqn0']//p[1]\")\n",
    "\n",
    "min_salary=[]\n",
    "for i in min_salaries:\n",
    "    min_salary.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the maximum salary\n",
    "max_salaries=driver.find_elements_by_xpath(\"//div[@class='d-flex mt-xxsm css-79elbk epuxyqn0']//p[2]\")\n",
    "\n",
    "max_salary=[]\n",
    "for i in max_salaries:\n",
    "    max_salary.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the average salary\n",
    "avg_salaries=driver.find_elements_by_xpath(\"//div[@class='col-12 col-lg-4 px-lg-0 d-flex align-items-baseline']\")\n",
    "\n",
    "avg_salary=[]\n",
    "for i in avg_salaries:\n",
    "    avg_salary.append(i.text.replace('\\n','').replace('/yr',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company names</th>\n",
       "      <th>minimum salary</th>\n",
       "      <th>maximum salary</th>\n",
       "      <th>average salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "      <td>₹4L</td>\n",
       "      <td>₹13L</td>\n",
       "      <td>₹6,28,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IBM</td>\n",
       "      <td>₹6L</td>\n",
       "      <td>₹26L</td>\n",
       "      <td>₹9,12,579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>₹6L</td>\n",
       "      <td>₹23L</td>\n",
       "      <td>₹12,00,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ericsson-Worldwide</td>\n",
       "      <td>₹4L</td>\n",
       "      <td>₹18L</td>\n",
       "      <td>₹8,05,346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>₹8L</td>\n",
       "      <td>₹16L</td>\n",
       "      <td>₹12,33,084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Delhivery</td>\n",
       "      <td>₹5L</td>\n",
       "      <td>₹1Cr</td>\n",
       "      <td>₹12,44,381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EXL Service</td>\n",
       "      <td>₹6L</td>\n",
       "      <td>₹20L</td>\n",
       "      <td>₹12,37,215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Optum</td>\n",
       "      <td>₹8L</td>\n",
       "      <td>₹20L</td>\n",
       "      <td>₹12,70,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ZS Associates</td>\n",
       "      <td>₹2L</td>\n",
       "      <td>₹22L</td>\n",
       "      <td>₹11,66,865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Optum Global Solutions</td>\n",
       "      <td>₹10L</td>\n",
       "      <td>₹17L</td>\n",
       "      <td>₹14,49,216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               company names minimum salary maximum salary average salary\n",
       "0  Tata Consultancy Services            ₹4L           ₹13L     ₹6,28,490 \n",
       "1                        IBM            ₹6L           ₹26L     ₹9,12,579 \n",
       "2                  Accenture            ₹6L           ₹23L    ₹12,00,000 \n",
       "3         Ericsson-Worldwide            ₹4L           ₹18L     ₹8,05,346 \n",
       "4         UnitedHealth Group            ₹8L           ₹16L    ₹12,33,084 \n",
       "5                  Delhivery            ₹5L           ₹1Cr    ₹12,44,381 \n",
       "6                EXL Service            ₹6L           ₹20L    ₹12,37,215 \n",
       "7                      Optum            ₹8L           ₹20L    ₹12,70,000 \n",
       "8              ZS Associates            ₹2L           ₹22L    ₹11,66,865 \n",
       "9     Optum Global Solutions           ₹10L           ₹17L    ₹14,49,216 "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salaries=pd.DataFrame({})\n",
    "salaries['company names']= company_names[:10]\n",
    "salaries['minimum salary']= min_salary[:10]\n",
    "salaries['maximum salary']= max_salary[:10]\n",
    "salaries['average salary']= avg_salary[:10]\n",
    "\n",
    "salaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6 : Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. Discount %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening web driver\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#giving url to webdriver\n",
    "url='https://www.flipkart.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"042058456d538a104e28c4426b394d2b\", element=\"e111b00d-fb07-4646-9772-94cddccef623\")>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#searching xpath on webpage\n",
    "search_bar=driver.find_element_by_xpath('//input[@class=\"_3704LK\"]')\n",
    "search_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#giving input in search bar\n",
    "search_bar.send_keys(\"sunglasses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#searching data and pressing button\n",
    "search_button=driver.find_element_by_xpath('//button[@class=\"L0Z3Pu\"]')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching brands of sunglasses\n",
    "brand=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "brand_names=[]\n",
    "for i in brand:\n",
    "    brand_names.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching product description of sunglasses\n",
    "product_desc=driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "product_description=[]\n",
    "for i in product_desc:\n",
    "    product_description.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching price of sunglasses\n",
    "price=driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "price_of_sunglass=[]\n",
    "for i in price:\n",
    "    price_of_sunglass.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching discount% of sunglasses\n",
    "discount=driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']\")\n",
    "discount_percentage=[]\n",
    "for i in discount:\n",
    "    discount_percentage.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#searching and clicking next button\n",
    "next_button=driver.find_element_by_xpath('//a[@class=\"_1LKTO3\"]')\n",
    "next_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching brands of sunglasses\n",
    "brand1=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "brand_names1=[]\n",
    "for i in brand1:\n",
    "    brand_names1.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching product description of sunglasses\n",
    "product_desc1=driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "product_description1=[]\n",
    "for i in product_desc1:\n",
    "    product_description1.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching price of sunglasses\n",
    "price1=driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "price_of_sunglass1=[]\n",
    "for i in price1:\n",
    "    price_of_sunglass1.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching discount% of sunglasses\n",
    "discount1=driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']\")\n",
    "discount_percentage1=[]\n",
    "for i in discount1:\n",
    "    discount_percentage1.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#searching and clicking next button\n",
    "next_button=driver.find_element_by_xpath('//a[@class=\"_1LKTO3\"]')\n",
    "next_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching brands of sunglasses\n",
    "brand2=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "brand_names2=[]\n",
    "for i in brand2:\n",
    "    brand_names2.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching product description of sunglasses\n",
    "product_desc2=driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "product_description2=[]\n",
    "for i in product_desc2:\n",
    "    product_description2.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching price of sunglasses\n",
    "price2=driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "price_of_sunglass2=[]\n",
    "for i in price2:\n",
    "    price_of_sunglass2.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching discount% of sunglasses\n",
    "discount2=driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']\")\n",
    "discount_percentage2=[]\n",
    "for i in discount2:\n",
    "    discount_percentage2.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "brands_list=brand_names+brand_names1+brand_names2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_descriptions=product_description+product_description1+product_description2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices=price_of_sunglass+price_of_sunglass1+price_of_sunglass2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "discounts=discount_percentage+discount_percentage1+discount_percentage2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "      <th>discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LIZA ANGEL</td>\n",
       "      <td>UV Protection Shield Sunglasses (54)</td>\n",
       "      <td>₹279</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>Mirrored, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kingsunglasses</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹299</td>\n",
       "      <td>88% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹513</td>\n",
       "      <td>35% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Aviator Sunglasses (54)</td>\n",
       "      <td>₹758</td>\n",
       "      <td>15% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>AISLIN</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (Free Size)</td>\n",
       "      <td>₹498</td>\n",
       "      <td>67% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹655</td>\n",
       "      <td>27% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection Aviator Sunglasses (88)</td>\n",
       "      <td>₹499</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Silver Kartz</td>\n",
       "      <td>UV Protection Aviator Sunglasses (58)</td>\n",
       "      <td>₹259</td>\n",
       "      <td>82% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Silver Kartz</td>\n",
       "      <td>UV Protection Aviator Sunglasses (Free Size)</td>\n",
       "      <td>₹269</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             brand                                        description price  \\\n",
       "0       LIZA ANGEL               UV Protection Shield Sunglasses (54)  ₹279   \n",
       "1   ROZZETTA CRAFT  Mirrored, UV Protection Wayfarer Sunglasses (F...  ₹499   \n",
       "2   kingsunglasses   UV Protection Rectangular Sunglasses (Free Size)  ₹299   \n",
       "3         Fastrack      UV Protection Wayfarer Sunglasses (Free Size)  ₹513   \n",
       "4         Fastrack              UV Protection Aviator Sunglasses (54)  ₹758   \n",
       "..             ...                                                ...   ...   \n",
       "95          AISLIN  UV Protection Retro Square Sunglasses (Free Size)  ₹498   \n",
       "96        Fastrack      UV Protection Wayfarer Sunglasses (Free Size)  ₹655   \n",
       "97  ROZZETTA CRAFT              UV Protection Aviator Sunglasses (88)  ₹499   \n",
       "98    Silver Kartz              UV Protection Aviator Sunglasses (58)  ₹259   \n",
       "99    Silver Kartz       UV Protection Aviator Sunglasses (Free Size)  ₹269   \n",
       "\n",
       "   discount  \n",
       "0   65% off  \n",
       "1   80% off  \n",
       "2   88% off  \n",
       "3   35% off  \n",
       "4   15% off  \n",
       "..      ...  \n",
       "95  67% off  \n",
       "96  27% off  \n",
       "97  77% off  \n",
       "98  82% off  \n",
       "99  77% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sunglasses=pd.DataFrame({})\n",
    "sunglasses['brand']= brands_list[:100]\n",
    "sunglasses['description']= product_descriptions[:100]\n",
    "sunglasses['price']= prices[:100]\n",
    "sunglasses['discount']= discounts[:100]\n",
    "\n",
    "sunglasses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link: https://www.flipkart.com/apple-iphone-11-black-64-gb-includes\u0002earpods-power\u0002adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace. you have to scrape the below mention attributes. These are\n",
    "Rating\n",
    "\n",
    "Review_summary\n",
    "\n",
    "Full review You have to scrape this data for first 100 reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activating the chrome browser\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(3)\n",
    "\n",
    "# Opening the website link\n",
    "url = \"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#empty list\n",
    "urls=[]\n",
    "review=[]\n",
    "full_review=[]\n",
    "stars=[]\n",
    "time.sleep(2)\n",
    "\n",
    "#scraping 10 pages of url\n",
    "url_1 = driver.find_elements_by_xpath(\"//a[@class='ge-49M _2Kfbh8']\")\n",
    "for i in url_1:\n",
    "    urls.append(i.get_attribute('href'))\n",
    "url_2 = driver.find_elements_by_xpath(\"//a[@class='ge-49M']\")\n",
    "for i in url_2:\n",
    "    urls.append(i.get_attribute('href'))\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    #scrapping the number of stars\n",
    "    for j in driver.find_elements_by_xpath(\"//div[@class='col _2wzgFH K0kLPL']/div[1]/div[1]\"):\n",
    "        stars.append(j.text)\n",
    "    #scrapping the short review\n",
    "    for k in driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\"):\n",
    "        review.append(k.text)\n",
    "    #for scrapping the complete review\n",
    "    for l in driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']/div/div\"):\n",
    "        full_review.append(l.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>full_review</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money\\n\\nThe iPhone 11 ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Super!</td>\n",
       "      <td>This is my first ever iPhone.\\nAnd I truly don...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Just wow!</td>\n",
       "      <td>The ultimate performance\\nCamera is superb\\nTh...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Terrific purchase</td>\n",
       "      <td>I use a Note10+ and have been using both iOS a...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Awesome</td>\n",
       "      <td>The phone is completely good\\nAs far as camera...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Decent product</td>\n",
       "      <td>Everything u ll like it when u use this iPhone...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 review                                        full_review  \\\n",
       "0             Brilliant  The Best Phone for the Money\\n\\nThe iPhone 11 ...   \n",
       "1        Simply awesome  Really satisfied with the Product I received.....   \n",
       "2      Perfect product!  Amazing phone with great cameras and better ba...   \n",
       "3     Worth every penny  Previously I was using one plus 3t it was a gr...   \n",
       "4   Best in the market!  Great iPhone very snappy experience as apple k...   \n",
       "..                  ...                                                ...   \n",
       "95               Super!  This is my first ever iPhone.\\nAnd I truly don...   \n",
       "96            Just wow!  The ultimate performance\\nCamera is superb\\nTh...   \n",
       "97    Terrific purchase  I use a Note10+ and have been using both iOS a...   \n",
       "98              Awesome  The phone is completely good\\nAs far as camera...   \n",
       "99       Decent product  Everything u ll like it when u use this iPhone...   \n",
       "\n",
       "   stars  \n",
       "0      5  \n",
       "1      5  \n",
       "2      5  \n",
       "3      5  \n",
       "4      5  \n",
       "..   ...  \n",
       "95     5  \n",
       "96     5  \n",
       "97     5  \n",
       "98     5  \n",
       "99     3  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making dataframe\n",
    "iphone = pd.DataFrame({})\n",
    "iphone['review']= review\n",
    "iphone['full_review']= full_review\n",
    "iphone['stars']= stars\n",
    "\n",
    "iphone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field.\n",
    "You have to scrape 4 attributes of each sneaker :\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. discount %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening web driver\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#giving url to webdriver\n",
    "url='https://www.flipkart.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"a63aa57ff91d0658d48b5ce0eec72e9a\", element=\"009e03bb-6753-4d03-ab9b-2dde2e65f96a\")>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#searching xpath on webpage\n",
    "search_bar=driver.find_element_by_xpath('//input[@class=\"_3704LK\"]')\n",
    "search_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#giving input in search bar\n",
    "search_bar.send_keys(\"sneakers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#searching data and pressing button\n",
    "search_button=driver.find_element_by_xpath('//button[@class=\"L0Z3Pu\"]')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching brands of sneakers\n",
    "brand=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "brand_names=[]\n",
    "for i in brand:\n",
    "    brand_names.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching product description of sunglasses\n",
    "product_desc=driver.find_elements_by_xpath(\"//a[@class='']\")\n",
    "product_description=[]\n",
    "for i in product_desc:\n",
    "    product_description.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching product description of sneakers\n",
    "product_desc=driver.find_elements_by_xpath(\"//div[@class='_2B099V']//a\")\n",
    "product_description=[]\n",
    "for i in product_desc:\n",
    "    product_description.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_list=[]\n",
    "for i in range(0,len(product_description),2):\n",
    "    new_list.append(product_description[i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching price of sneakers\n",
    "price=driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "price_of_sneakers=[]\n",
    "for i in price:\n",
    "    price_of_sneakers.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching discount% of sneakers\n",
    "discount=driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']\")\n",
    "discount_percentage=[]\n",
    "for i in discount:\n",
    "    discount_percentage.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#searching and clicking next button\n",
    "next_button=driver.find_element_by_xpath('//a[@class=\"_1LKTO3\"]')\n",
    "next_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching brands of sneakers\n",
    "brand1=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "brand_names1=[]\n",
    "for i in brand1:\n",
    "    brand_names1.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching product description of sneakers\n",
    "product_desc1=driver.find_elements_by_xpath(\"//div[@class='_2B099V']//a\")\n",
    "product_description1=[]\n",
    "for i in product_desc1:\n",
    "    product_description1.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_list1=[]\n",
    "for i in range(0,len(product_description1),2):\n",
    "    new_list1.append(product_description1[i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching price of sneakers\n",
    "price1=driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "price_of_sneakers1=[]\n",
    "for i in price1:\n",
    "    price_of_sneakers1.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching discount% of sneakers\n",
    "discount1=driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']\")\n",
    "discount_percentage1=[]\n",
    "for i in discount1:\n",
    "    discount_percentage1.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#searching and clicking next button\n",
    "next_button=driver.find_element_by_xpath('/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[4]')\n",
    "next_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching brands of sneakers\n",
    "brand2=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "brand_names2=[]\n",
    "for i in brand2:\n",
    "    brand_names2.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching product description of sneakers\n",
    "product_desc2=driver.find_elements_by_xpath(\"//div[@class='_2B099V']//a\")\n",
    "product_description2=[]\n",
    "for i in product_desc2:\n",
    "    product_description2.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_list2=[]\n",
    "for i in range(0,len(product_description2),2):\n",
    "    new_list2.append(product_description2[i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching price of sneakers\n",
    "price2=driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "price_of_sneakers2=[]\n",
    "for i in price2:\n",
    "    price_of_sneakers2.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching discount% of sneakers\n",
    "discount2=driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']\")\n",
    "discount_percentage2=[]\n",
    "for i in discount2:\n",
    "    discount_percentage2.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "brands_list=brand_names+brand_names1+brand_names2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_descriptions=new_list+new_list1+new_list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices=price_of_sneakers+price_of_sneakers1+price_of_sneakers2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "discounts=discount_percentage+discount_percentage1+discount_percentage2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "      <th>discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Echor</td>\n",
       "      <td>Fashion Sneakers Sneakers For Men</td>\n",
       "      <td>₹569</td>\n",
       "      <td>43% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>2 Pairs Sneakers For Men</td>\n",
       "      <td>₹494</td>\n",
       "      <td>75% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>Men's Casual Shoes in White Color Walking Runn...</td>\n",
       "      <td>₹399</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CALCADOS</td>\n",
       "      <td>Fashion Outdoor Canvas Casual Light Weight Par...</td>\n",
       "      <td>₹748</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PEHANOSA</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹495</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹1,229</td>\n",
       "      <td>56% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>bluemaker</td>\n",
       "      <td>casual shoe for men Sneakers For Men</td>\n",
       "      <td>₹449</td>\n",
       "      <td>55% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>kardam&amp;sons</td>\n",
       "      <td>Karda Casual Sneakers and Gym Shoes for Men's ...</td>\n",
       "      <td>₹430</td>\n",
       "      <td>74% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>D-SNEAKERZ</td>\n",
       "      <td>Casual , Partywear Sneakers Shoes For Men's An...</td>\n",
       "      <td>₹384</td>\n",
       "      <td>61% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Edoeviv</td>\n",
       "      <td>Luxury Branded Fashionable Men's Casual Walkin...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>37% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           brand                                        description   price  \\\n",
       "0          Echor                  Fashion Sneakers Sneakers For Men    ₹569   \n",
       "1         Chevit                           2 Pairs Sneakers For Men    ₹494   \n",
       "2   Robbie jones  Men's Casual Shoes in White Color Walking Runn...    ₹399   \n",
       "3       CALCADOS  Fashion Outdoor Canvas Casual Light Weight Par...    ₹748   \n",
       "4       PEHANOSA                                   Sneakers For Men    ₹495   \n",
       "..           ...                                                ...     ...   \n",
       "95          PUMA                                   Sneakers For Men  ₹1,229   \n",
       "96     bluemaker               casual shoe for men Sneakers For Men    ₹449   \n",
       "97   kardam&sons  Karda Casual Sneakers and Gym Shoes for Men's ...    ₹430   \n",
       "98    D-SNEAKERZ  Casual , Partywear Sneakers Shoes For Men's An...    ₹384   \n",
       "99       Edoeviv  Luxury Branded Fashionable Men's Casual Walkin...    ₹499   \n",
       "\n",
       "   discount  \n",
       "0   43% off  \n",
       "1   75% off  \n",
       "2   60% off  \n",
       "3   62% off  \n",
       "4   50% off  \n",
       "..      ...  \n",
       "95  56% off  \n",
       "96  55% off  \n",
       "97  74% off  \n",
       "98  61% off  \n",
       "99  37% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sneakers=pd.DataFrame({})\n",
    "sneakers['brand']= brands_list[:100]\n",
    "sneakers['description']= product_descriptions[:100]\n",
    "sneakers['price']= prices[:100]\n",
    "sneakers['discount']= discounts[:100]\n",
    "\n",
    "sneakers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q9: Go to the link - https://www.myntra.com/shoes\n",
    "Set Price filter to “Rs. 6649 to Rs. 13099” , Color filter to “Black”,And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe description, price of the shoe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening web driver\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#giving url to webdriver\n",
    "url='https://www.myntra.com/shoes'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#searching filter and pressing button\n",
    "filter_button=driver.find_element_by_xpath('/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label/div')\n",
    "filter_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#searching filter and pressing button\n",
    "filter_button=driver.find_element_by_xpath('/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label')\n",
    "filter_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching brands of shoes\n",
    "brand=driver.find_elements_by_xpath(\"//h3[@class='product-brand']\")\n",
    "brand_names=[]\n",
    "for i in brand:\n",
    "    brand_names.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching product description of shoes\n",
    "product_desc=driver.find_elements_by_xpath(\"//h4[@class='product-product']\")\n",
    "product_description=[]\n",
    "for i in product_desc:\n",
    "    product_description.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching price of shoes\n",
    "price=driver.find_elements_by_xpath(\"//div[@class='product-price']\")\n",
    "price_of_shoes=[]\n",
    "for i in price:\n",
    "    price_of_shoes.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#searching and clicking next button\n",
    "next_button=driver.find_element_by_xpath('//li[@class=\"pagination-next\"]')\n",
    "next_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching brands of shoes\n",
    "brand1=driver.find_elements_by_xpath(\"//h3[@class='product-brand']\")\n",
    "brand_names1=[]\n",
    "for i in brand1:\n",
    "    brand_names1.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching product description of shoes\n",
    "product_desc1=driver.find_elements_by_xpath(\"//h4[@class='product-product']\")\n",
    "product_description1=[]\n",
    "for i in product_desc1:\n",
    "    product_description1.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching price of shoes\n",
    "price1=driver.find_elements_by_xpath(\"//div[@class='product-price']\")\n",
    "price_of_shoes1=[]\n",
    "for i in price1:\n",
    "    price_of_shoes1.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "brands_list=brand_names+brand_names1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_descriptions=product_description+product_description1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices=price_of_shoes+price_of_shoes1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nike</td>\n",
       "      <td>LEBRON XVIII Basketball Shoes</td>\n",
       "      <td>Rs. 12316Rs. 17595(30% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Men Driving Shoes</td>\n",
       "      <td>Rs. 11999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men AIR ZOOM Running Shoes</td>\n",
       "      <td>Rs. 7721Rs. 10295(25% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Men Sneakers</td>\n",
       "      <td>Rs. 9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Men Sneakers</td>\n",
       "      <td>Rs. 9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>KLEAT</td>\n",
       "      <td>Men Woven Design Loafers</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>J.FONTINI</td>\n",
       "      <td>Men Solid Loafers</td>\n",
       "      <td>Rs. 7990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Lacoste</td>\n",
       "      <td>Men Colourblocked Sneakers</td>\n",
       "      <td>Rs. 8650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lacoste</td>\n",
       "      <td>Men Woven Design Sneakers</td>\n",
       "      <td>Rs. 8500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Bugatti</td>\n",
       "      <td>Men Perforated Mule Sneakers</td>\n",
       "      <td>Rs. 6999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        brand                    description                        price\n",
       "0        Nike  LEBRON XVIII Basketball Shoes  Rs. 12316Rs. 17595(30% OFF)\n",
       "1        ALDO              Men Driving Shoes                    Rs. 11999\n",
       "2        Nike     Men AIR ZOOM Running Shoes   Rs. 7721Rs. 10295(25% OFF)\n",
       "3        ALDO                   Men Sneakers                     Rs. 9999\n",
       "4        ALDO                   Men Sneakers                     Rs. 9999\n",
       "..        ...                            ...                          ...\n",
       "95      KLEAT       Men Woven Design Loafers                     Rs. 7999\n",
       "96  J.FONTINI              Men Solid Loafers                     Rs. 7990\n",
       "97    Lacoste     Men Colourblocked Sneakers                     Rs. 8650\n",
       "98    Lacoste      Men Woven Design Sneakers                     Rs. 8500\n",
       "99    Bugatti   Men Perforated Mule Sneakers                     Rs. 6999\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shoes=pd.DataFrame({})\n",
    "shoes['brand']= brands_list[:100]\n",
    "shoes['description']= product_descriptions[:100]\n",
    "shoes['price']= prices[:100]\n",
    "\n",
    "shoes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q10: Go to webpage https://www.amazon.in/\n",
    "Enter “Laptop” in the search field and then click the search icon.\n",
    "Then set CPU Type filter to “Intel Core i7” and “Intel Core i9”.After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:\n",
    "1. title\n",
    "2. Ratings\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening web driver\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#giving url to webdriver\n",
    "url='https://www.amazon.in/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"0cc77d6e4c896b0a1e85e2a27395cb67\", element=\"f751eb15-2eb1-47ae-9e98-23e6813901cc\")>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#searching xpath on webpage\n",
    "search_bar=driver.find_element_by_xpath('//input[@class=\"nav-input nav-progressive-attribute\"]')\n",
    "search_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#giving input in search bar\n",
    "search_bar.send_keys(\"laptops\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#searching data and pressing button\n",
    "search_button=driver.find_element_by_xpath('//div[@class=\"nav-search-submit nav-sprite\"]')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_button=driver.find_elements_by_xpath('//a[@class=\"a-link-normal s-navigation-item\"]//span')\n",
    "for i in filter_button:\n",
    "    if i.text=='Intel Core i7':\n",
    "        i.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_button=driver.find_elements_by_xpath('//a[@class=\"a-link-normal s-navigation-item\"]//span')\n",
    "for i in filter_button:\n",
    "    if i.text=='Intel Core i9':\n",
    "        i.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "title=driver.find_elements_by_xpath(\"//h2[@class='a-size-mini a-spacing-none a-color-base s-line-clamp-2']\")\n",
    "product_title=[]\n",
    "for i in title:\n",
    "    product_title.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "url =driver.find_elements_by_xpath(\"//a[@class='a-link-normal a-text-normal']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.amazon.in/HP-Pavilion-Graphics-35-56cms-14-dv0058TU/dp/B08WB857GB/ref=sr_1_1?dchild=1&keywords=laptops&qid=1626078362&refinements=p_n_feature_thirteen_browse-bin%3A12598163031%7C16757432031&rnid=12598141031&s=computers&sr=1-1',\n",
       " 'https://www.amazon.in/Notebook-Horizon-i7-10510U-Graphics-XMA1904-AF/dp/B089F2W1KW/ref=sr_1_2?dchild=1&keywords=laptops&qid=1626078362&refinements=p_n_feature_thirteen_browse-bin%3A12598163031%7C16757432031&rnid=12598141031&s=computers&sr=1-2',\n",
       " 'https://www.amazon.in/HP-Pavilion-Touchscreen-Convertible-14-dw1040TU/dp/B08R843NHL/ref=sr_1_3?dchild=1&keywords=laptops&qid=1626078362&refinements=p_n_feature_thirteen_browse-bin%3A12598163031%7C16757432031&rnid=12598141031&s=computers&sr=1-3',\n",
       " 'https://www.amazon.in/Dell-i7-1165G7-Inspiron-5410-D560469WIN9S/dp/B095S9NJ4S/ref=sr_1_4?dchild=1&keywords=laptops&qid=1626078362&refinements=p_n_feature_thirteen_browse-bin%3A12598163031%7C16757432031&rnid=12598141031&s=computers&sr=1-4',\n",
       " 'https://www.amazon.in/Lenovo-Legion-Gaming-GeForce-81SY00U7IN/dp/B092MRQCJ6/ref=sr_1_5?dchild=1&keywords=laptops&qid=1626078362&refinements=p_n_feature_thirteen_browse-bin%3A12598163031%7C16757432031&rnid=12598141031&s=computers&sr=1-5',\n",
       " 'https://www.amazon.in/Lenovo-Ideapad-Graphics-Graphite-82FG0117IN/dp/B092MV9ZF6/ref=sr_1_6?dchild=1&keywords=laptops&qid=1626078362&refinements=p_n_feature_thirteen_browse-bin%3A12598163031%7C16757432031&rnid=12598141031&s=computers&sr=1-6',\n",
       " 'https://www.amazon.in/MSI-i7-10750H-IPS-Level-Windows-10SDR-1280IN/dp/B093L8JCZV/ref=sr_1_7?dchild=1&keywords=laptops&qid=1626078362&refinements=p_n_feature_thirteen_browse-bin%3A12598163031%7C16757432031&rnid=12598141031&s=computers&sr=1-7',\n",
       " 'https://www.amazon.in/Lenovo-Touchscreen-Fingerprint-Graphite-82HS0092IN/dp/B08WRZQBQ6/ref=sr_1_8?dchild=1&keywords=laptops&qid=1626078362&refinements=p_n_feature_thirteen_browse-bin%3A12598163031%7C16757432031&rnid=12598141031&s=computers&sr=1-8',\n",
       " 'https://www.amazon.in/ASUS-VivoBook-i7-1165G7-Graphics-S433EA-AM702TS/dp/B08SN9GJXH/ref=sr_1_9?dchild=1&keywords=laptops&qid=1626078362&refinements=p_n_feature_thirteen_browse-bin%3A12598163031%7C16757432031&rnid=12598141031&s=computers&sr=1-9',\n",
       " 'https://www.amazon.in/ASUS-Zephyrus-i7-10750H-RTX-2080-GX701LXS-HG002TS/dp/B08PFD2Z9M/ref=sr_1_10?dchild=1&keywords=laptops&qid=1626078362&refinements=p_n_feature_thirteen_browse-bin%3A12598163031%7C16757432031&rnid=12598141031&s=computers&sr=1-10',\n",
       " 'https://www.amazon.in/ASUS-Zephyrus-i7-10750H-RTX-2070-Super-GX701LWS-HG002TS/dp/B08PFDCZD3/ref=sr_1_11?dchild=1&keywords=laptops&qid=1626078362&refinements=p_n_feature_thirteen_browse-bin%3A12598163031%7C16757432031&rnid=12598141031&s=computers&sr=1-11',\n",
       " 'https://www.amazon.in/Dell-15-6-inch-i7-10750H-NVIDIA1650-D560260WIN9BE/dp/B08H9PTSYR/ref=sr_1_12?dchild=1&keywords=laptops&qid=1626078362&refinements=p_n_feature_thirteen_browse-bin%3A12598163031%7C16757432031&rnid=12598141031&s=computers&sr=1-12',\n",
       " 'https://www.amazon.in/gp/slredirect/picassoRedirect.html/ref=pa_sp_mtf_computers_sr_pg1_1?ie=UTF8&adId=A02653902UKZ2EJPLDFRL&url=%2FNotebook-Horizon-i5-10210U-Graphics-XMA1904-AR%2Fdp%2FB089F5JGM1%2Fref%3Dsr_1_13_sspa%3Fdchild%3D1%26keywords%3Dlaptops%26qid%3D1626078362%26refinements%3Dp_n_feature_thirteen_browse-bin%253A12598163031%257C16757432031%26rnid%3D12598141031%26s%3Dcomputers%26sr%3D1-13-spons%26psc%3D1&qualifier=1626078362&id=8139795199058089&widgetName=sp_mtf',\n",
       " 'https://www.amazon.in/gp/slredirect/picassoRedirect.html/ref=pa_sp_mtf_computers_sr_pg1_1?ie=UTF8&adId=A014119429EI5XB7GMHC7&url=%2FMSI-GS66-Stealth-i7-10875H-10SFS-488IN%2Fdp%2FB08KG3CHVR%2Fref%3Dsr_1_14_sspa%3Fdchild%3D1%26keywords%3Dlaptops%26qid%3D1626078362%26refinements%3Dp_n_feature_thirteen_browse-bin%253A12598163031%257C16757432031%26rnid%3D12598141031%26s%3Dcomputers%26sr%3D1-14-spons%26psc%3D1&qualifier=1626078362&id=8139795199058089&widgetName=sp_mtf',\n",
       " 'https://www.amazon.in/Lenovo-ThinkPad-Graphics-Aluminium-20TDS0G200/dp/B095SPWBKF/ref=sr_1_15?dchild=1&keywords=laptops&qid=1626078362&refinements=p_n_feature_thirteen_browse-bin%3A12598163031%7C16757432031&rnid=12598141031&s=computers&sr=1-15',\n",
       " 'https://www.amazon.in/MSI-i7-10750H-IPS-Level-Windows-10SCXR-654IN/dp/B093L8QGL7/ref=sr_1_16?dchild=1&keywords=laptops&qid=1626078362&refinements=p_n_feature_thirteen_browse-bin%3A12598163031%7C16757432031&rnid=12598141031&s=computers&sr=1-16',\n",
       " 'https://www.amazon.in/ASUS-ZenBook-i7-1165G7-Graphics-UX425EA-BM701TS/dp/B08M4SWRR5/ref=sr_1_17?dchild=1&keywords=laptops&qid=1626078362&refinements=p_n_feature_thirteen_browse-bin%3A12598163031%7C16757432031&rnid=12598141031&s=computers&sr=1-17',\n",
       " 'https://www.amazon.in/Lenovo-Touchscreen-Fingerprint-Aluminium-82BH004HIN/dp/B08P3M22QQ/ref=sr_1_18?dchild=1&keywords=laptops&qid=1626078362&refinements=p_n_feature_thirteen_browse-bin%3A12598163031%7C16757432031&rnid=12598141031&s=computers&sr=1-18',\n",
       " 'https://www.amazon.in/Dell-Inspiron-i7-1165G7-Integrated-D560414WIN9S/dp/B0919LL313/ref=sr_1_19?dchild=1&keywords=laptops&qid=1626078362&refinements=p_n_feature_thirteen_browse-bin%3A12598163031%7C16757432031&rnid=12598141031&s=computers&sr=1-19',\n",
       " 'https://www.amazon.in/ASUS-TUF-F15-i7-11370H-FX516PE-HN088TS/dp/B094RDLV5P/ref=sr_1_20?dchild=1&keywords=laptops&qid=1626078362&refinements=p_n_feature_thirteen_browse-bin%3A12598163031%7C16757432031&rnid=12598141031&s=computers&sr=1-20',\n",
       " 'https://www.amazon.in/HP-Pavilion-Gaming-Laptop-15-DK1511TX/dp/B0972H63VL/ref=sr_1_21?dchild=1&keywords=laptops&qid=1626078362&refinements=p_n_feature_thirteen_browse-bin%3A12598163031%7C16757432031&rnid=12598141031&s=computers&sr=1-21',\n",
       " 'https://www.amazon.in/Renewed-Lenovo-Windows-Graphics-81YU006HIN/dp/B098QBPB4Q/ref=sr_1_22?dchild=1&keywords=laptops&qid=1626078362&refinements=p_n_feature_thirteen_browse-bin%3A12598163031%7C16757432031&rnid=12598141031&s=computers&sr=1-22',\n",
       " 'https://www.amazon.in/Dell-1366x768-Integrated-Graphics-Latitude/dp/B09752NVNF/ref=sr_1_23?dchild=1&keywords=laptops&qid=1626078362&refinements=p_n_feature_thirteen_browse-bin%3A12598163031%7C16757432031&rnid=12598141031&s=computers&sr=1-23',\n",
       " 'https://www.amazon.in/HP-Pavilion-13-3-inch-Ceramic-13-bb0078TU/dp/B09839P9XB/ref=sr_1_24?dchild=1&keywords=laptops&qid=1626078362&refinements=p_n_feature_thirteen_browse-bin%3A12598163031%7C16757432031&rnid=12598141031&s=computers&sr=1-24',\n",
       " 'https://www.amazon.in/Lenovo-Carbon-Ultra-Light-Material-82EV003WIN/dp/B08ZCLMFHD/ref=sr_1_25?dchild=1&keywords=laptops&qid=1626078362&refinements=p_n_feature_thirteen_browse-bin%3A12598163031%7C16757432031&rnid=12598141031&s=computers&sr=1-25',\n",
       " 'https://www.amazon.in/ASUS-i7-10750H-Graphics-Windows-G512LU-HN263TS/dp/B08CR6C9LJ/ref=sr_1_26?dchild=1&keywords=laptops&qid=1626078362&refinements=p_n_feature_thirteen_browse-bin%3A12598163031%7C16757432031&rnid=12598141031&s=computers&sr=1-26']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_url=[]\n",
    "for i in url:\n",
    "    product_url.append(i.get_attribute('href'))\n",
    "product_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4.4 out of 5',\n",
       " '4.4 out of 5',\n",
       " '4 out of 5',\n",
       " '4.6 out of 5',\n",
       " '4.3 out of 5',\n",
       " '4.3 out of 5',\n",
       " '3.8 out of 5',\n",
       " '4 out of 5',\n",
       " '4.4 out of 5',\n",
       " '3.6 out of 5']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_rating=[]\n",
    "for i in product_url:\n",
    "    driver.get(i)\n",
    "    try:\n",
    "        rating = driver.find_element_by_xpath(\"//span[@class='a-size-base a-nowrap']\")\n",
    "        product_rating.append(rating.text)\n",
    "    except:\n",
    "        product_rating.append('-')\n",
    "product_rating[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "price=driver.find_elements_by_xpath(\"//span[@class='a-price']\")\n",
    "product_price=[]\n",
    "for i in price:\n",
    "    product_price.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HP Pavilion (2021) Thin &amp; Light 11th Gen Core ...</td>\n",
       "      <td>4.4 out of 5</td>\n",
       "      <td>₹99,990.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i7-1...</td>\n",
       "      <td>4.4 out of 5</td>\n",
       "      <td>₹1,16,730.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HP Pavilion x360 (2021) 14\" (35.56cms) FHD Tou...</td>\n",
       "      <td>4 out of 5</td>\n",
       "      <td>₹1,04,990.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dell 14 (2021) i7-1165G7 2in1 Touch Screen Lap...</td>\n",
       "      <td>4.6 out of 5</td>\n",
       "      <td>₹76,904.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lenovo Legion Y540 Intel Core i7 9th Gen 15.6”...</td>\n",
       "      <td>4.3 out of 5</td>\n",
       "      <td>₹1,42,900.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lenovo Ideapad 5 Intel i7 11th Gen 15.6\" Thin ...</td>\n",
       "      <td>4.3 out of 5</td>\n",
       "      <td>₹1,07,490.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MSI GF65 Thin, Intel i7-10750H, 15.6\" FHD (39....</td>\n",
       "      <td>3.8 out of 5</td>\n",
       "      <td>₹100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lenovo IdeaPad Flex 5 11th Gen Intel Core i7 1...</td>\n",
       "      <td>4 out of 5</td>\n",
       "      <td>₹87,301.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ASUS VivoBook S S14 Intel Core i7-1165G7 11th ...</td>\n",
       "      <td>4.4 out of 5</td>\n",
       "      <td>₹84,990.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ASUS ROG Zephyrus S17 (2020), 17.3\" FHD 300Hz/...</td>\n",
       "      <td>3.6 out of 5</td>\n",
       "      <td>₹73,990.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title        rating  \\\n",
       "0  HP Pavilion (2021) Thin & Light 11th Gen Core ...  4.4 out of 5   \n",
       "1  Mi Notebook Horizon Edition 14 Intel Core i7-1...  4.4 out of 5   \n",
       "2  HP Pavilion x360 (2021) 14\" (35.56cms) FHD Tou...    4 out of 5   \n",
       "3  Dell 14 (2021) i7-1165G7 2in1 Touch Screen Lap...  4.6 out of 5   \n",
       "4  Lenovo Legion Y540 Intel Core i7 9th Gen 15.6”...  4.3 out of 5   \n",
       "5  Lenovo Ideapad 5 Intel i7 11th Gen 15.6\" Thin ...  4.3 out of 5   \n",
       "6  MSI GF65 Thin, Intel i7-10750H, 15.6\" FHD (39....  3.8 out of 5   \n",
       "7  Lenovo IdeaPad Flex 5 11th Gen Intel Core i7 1...    4 out of 5   \n",
       "8  ASUS VivoBook S S14 Intel Core i7-1165G7 11th ...  4.4 out of 5   \n",
       "9  ASUS ROG Zephyrus S17 (2020), 17.3\" FHD 300Hz/...  3.6 out of 5   \n",
       "\n",
       "          price  \n",
       "0    ₹99,990.00  \n",
       "1  ₹1,16,730.00  \n",
       "2  ₹1,04,990.00  \n",
       "3    ₹76,904.00  \n",
       "4  ₹1,42,900.00  \n",
       "5  ₹1,07,490.00  \n",
       "6       ₹100.00  \n",
       "7    ₹87,301.00  \n",
       "8    ₹84,990.00  \n",
       "9    ₹73,990.00  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laptops=pd.DataFrame({})\n",
    "laptops['title']= product_title[:10]\n",
    "laptops['rating']= product_rating[:10]\n",
    "laptops['price']= product_price[:10]\n",
    "\n",
    "laptops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
